[1mdiff --git a/backend/requirements.txt b/backend/requirements.txt[m
[1mindex de8d515..3ab8444 100644[m
[1m--- a/backend/requirements.txt[m
[1m+++ b/backend/requirements.txt[m
[36m@@ -14,4 +14,5 @@[m [mscipy[m
 python-multipart[m
 passlib[bcrypt][m
 email-validator[m
[31m-pillow[m
\ No newline at end of file[m
[32m+[m[32mpillow[m
[32m+[m[32mnumpy[m
\ No newline at end of file[m
[1mdiff --git a/backend/scripts/update_blog_keywords.py b/backend/scripts/update_blog_keywords.py[m
[1mindex f53b1dd..151c326 100644[m
[1m--- a/backend/scripts/update_blog_keywords.py[m
[1m+++ b/backend/scripts/update_blog_keywords.py[m
[36m@@ -1,31 +1,40 @@[m
 import sqlite3[m
 import os[m
[32m+[m[32mimport sys[m
 import json[m
[31m-[m
 from pathlib import Path[m
 from tqdm import tqdm[m
[32m+[m[32mfrom tqdm.asyncio import tqdm_asyncio   # kept: you may still want async later[m
 [m
 from ..connection.mongodb import restaurant_keywords_collection[m
 from ..services.generate_embedding import embed_small[m
 [m
[32m+[m[32m# ────────────────────────────────────────────────────────────────────────────────[m
[32m+[m[32m# CONSTANTS (unchanged)[m
 LAST_KEYWORD_ID = 8749[m
[31m-SQLITE_DB_PATH = Path(__file__).parent.parent.parent / ".test" / "data" / "backup" / "seoul_restaurants.sqlite"[m
[31m-[m
[31m-UPLOAD_KEYWORDS = False [m
[32m+[m[32mSQLITE_DB_PATH = ([m
[32m+[m[32m    Path(__file__).parent.parent.parent[m
[32m+[m[32m    / ".test"[m
[32m+[m[32m    / "data"[m
[32m+[m[32m    / "backup"[m
[32m+[m[32m    / "seoul_restaurants.sqlite"[m
[32m+[m[32m)[m
[32m+[m[32mUPLOAD_KEYWORDS = True        # ← set to True to perform the MongoDB update[m
[32m+[m[32mBATCH_SIZE = 512              # openai text-embedding-3-small max = 512 inputs[m
 [m
[31m-def main():[m
[32m+[m[32m# ────────────────────────────────────────────────────────────────────────────────[m
[32m+[m[32mdef main() -> None:[m
[32m+[m[32m    # 1. 𝗟𝗼𝗮𝗱 𝗻𝗲𝘄 𝗿𝗼𝘄𝘀 𝗳𝗿𝗼𝗺 SQLite[m
     connection = sqlite3.connect(SQLITE_DB_PATH)[m
     cursor = connection.cursor()[m
 [m
[31m-    print("Fetching keywords from SQLite database...")[m
[32m+[m[32m    print("Fetching keywords from SQLite database…")[m
     cursor.execute("SELECT * FROM keywords WHERE k_id > ?", (LAST_KEYWORD_ID,))[m
     rows = cursor.fetchall()[m
     print(f"Fetched {len(rows)} new keywords.")[m
 [m
[31m-    # parse a single keyword for sample[m
[32m+[m[32m    # optional sanity samples (kept)[m
     sample_row = rows[0] if rows else None[m
[31m-    print(f"Sample row: {sample_row}")[m
[31m-    print(len(sample_row))[m
     if sample_row:[m
         sample_keyword = {[m
             "k_id": sample_row[0],[m
[36m@@ -33,76 +42,143 @@[m [mdef main():[m
             "r_id": sample_row[2],[m
             "name": sample_row[3],[m
             "title": sample_row[4],[m
[31m-            "keywords": json.loads(sample_row[5]) if sample_row[5] else [][m
[32m+[m[32m            "keywords": json.loads(sample_row[5]) if sample_row[5] else [],[m
         }[m
[31m-        print(f"Sample keyword: {sample_keyword}")[m
[32m+[m[32m        print(f"Sample keyword row: {sample_keyword}")[m
 [m
[31m-    # prepare mongodb documents[m
[31m-    sample_row = restaurant_keywords_collection.find_one({"k_id": LAST_KEYWORD_ID})[m
[31m-    if sample_row:[m
[31m-        print(f"Sample MongoDB document: {sample_row}")[m
[31m-    [m
[31m-    # insert a sample document for sanity check[m
[31m-    sample_doc = {[m
[31m-        "k_id": LAST_KEYWORD_ID + 1,[m
[31m-        "b_id": sample_row["b_id"] if sample_row else None,[m
[31m-        "r_id": sample_row["r_id"] if sample_row else None,[m
[31m-        "name": "Sample Keyword",[m
[31m-        "title": "Sample Title",[m
[31m-        "keywords": ["sample", "keyword"][m
[31m-    }[m
[31m-    print(f"Sample document to insert: {sample_doc}")[m
[31m-[m
[31m-    if UPLOAD_KEYWORDS:[m
[31m-        print("Uploading keywords to MongoDB...")[m
[31m-        # Insert new keywords into MongoDB[m
[31m-        restaurant_keywords_collection.insert_many([[m
[31m-            {[m
[31m-                "k_id": row[0],[m
[31m-                "b_id": row[1],[m
[31m-                "r_id": row[2],[m
[31m-                "name": row[3],[m
[31m-                "title": row[4],[m
[31m-                "keywords": json.loads(row[5]) if row[5] else [][m
[31m-            } for row in rows[m
[31m-        ])[m
[31m-        print(f"Uploaded {len(rows)} new keywords to MongoDB.")[m
[31m-    [m
[31m-    # delete the inserted sample document[m
[31m-    if UPLOAD_KEYWORDS:[m
[31m-        print("Deleting sample document from MongoDB...")[m
[31m-        restaurant_keywords_collection.delete_one({"k_id": LAST_KEYWORD_ID + 1})[m
[31m-        print("Sample document deleted.")[m
[31m-[m
[31m-    if not rows or not UPLOAD_KEYWORDS:[m
[31m-        print("No new keywords to upload or upload is disabled.")[m
[32m+[m[32m    if not rows:[m
[32m+[m[32m        print("Nothing new to process — exiting.")[m
         return[m
[31m-    [m
[31m-    # Get all keywords from MongoDB[m
[31m-    print("Fetching all keywords from MongoDB...")[m
[31m-    existing_keywords = list(restaurant_keywords_collection.find({"k_id": {"$gt": LAST_KEYWORD_ID}}))[m
[31m-    print(f"Found {len(existing_keywords)} existing keywords in MongoDB.")[m
 [m
[31m-    # update the rows with new keywords[m
[31m-    [m
[31m-    [m
[31m-    # Generate embeddings for the keywords[m
[31m-    print("Generating embeddings for keywords...")[m
[31m-    for row in tqdm(rows):[m
[31m-        keywords = json.loads(row[5]) if row[5] else [][m
[31m-        if not keywords:[m
[31m-            continue[m
[31m-        [m
[31m-        embeddings = embed_small(keywords)[m
[31m-        row["keywords"] = [[m
[31m-            {[m
[31m-                "keyword": keywords[i],[m
[31m-                "embedding": embeddings[i].tolist() if embeddings[i] is not None else None[m
[31m-            } for i in range(len(keywords))[m
[31m-        ][m
[31m-    [m
[31m-    # [m
[32m+[m[32m    if not UPLOAD_KEYWORDS:[m
[32m+[m[32m        print("UPLOAD_KEYWORDS == False → dry-run only — exiting.")[m
[32m+[m[32m        return[m
[32m+[m
[32m+[m[32m    # 2. 𝗧𝗿𝗮𝗻𝘀𝗳𝗼𝗿𝗺 rows → list[dict] for easier handling[m
[32m+[m[32m    new_rows = [[m
[32m+[m[32m        {[m
[32m+[m[32m            "k_id": row[0],[m
[32m+[m[32m            "b_id": row[1],[m
[32m+[m[32m            "r_id": row[2],[m
[32m+[m[32m            "name": row[3],[m
[32m+[m[32m            "title": row[4],[m
[32m+[m[32m            "keywords": json.loads(row[5]) if row[5] else [],[m
[32m+[m[32m        }[m
[32m+[m[32m        for row in rows[m
[32m+[m[32m    ][m
[32m+[m
[32m+[m[32m    # ────────────────────────────────────────────────────────────────────────[m
[32m+[m[32m    # 3. 𝗙𝗲𝘁𝗰𝗵 𝗲𝘅𝗶𝘀𝘁𝗶𝗻𝗴 MongoDB docs once; build a fast lookup map[m
[32m+[m[32m    from pymongo import UpdateOne[m
[32m+[m
[32m+[m[32m    print("Loading existing restaurant keyword docs from MongoDB…")[m
[32m+[m[32m    existing_docs = list(restaurant_keywords_collection.find({}, {"_id": 0}))[m
[32m+[m[32m    rmap: dict[int, dict] = {doc["r_id"]: doc for doc in existing_docs}[m
[32m+[m[32m    print(f"Loaded {len(rmap)} existing docs.")[m
[32m+[m
[32m+[m[32m    # ────────────────────────────────────────────────────────────────────────[m
[32m+[m[32m    # 4. 𝗠𝗲𝗿𝗴𝗲 𝗸𝗲𝘆𝘄𝗼𝗿𝗱𝘀 𝗶𝗻-𝗺𝗲𝗺𝗼𝗿𝘆 (keywords array only)[m
[32m+[m[32m    for row in tqdm(new_rows, desc="Merging keywords"):[m
[32m+[m[32m        r_id = row["r_id"][m
[32m+[m[32m        kw_strings = row["keywords"][m
[32m+[m
[32m+[m[32m        # fetch or create a minimal schema-compliant document[m
[32m+[m[32m        doc = rmap.get(r_id)[m
[32m+[m[32m        if doc is None:[m
[32m+[m[32m            doc = {"r_id": r_id, "keywords": []}[m
[32m+[m[32m            rmap[r_id] = doc[m
[32m+[m
[32m+[m[32m        # build index {keyword→obj} for O(1) access[m
[32m+[m[32m        kw_index = {item["keyword"]: item for item in doc["keywords"]}[m
[32m+[m
[32m+[m[32m        # merge/update[m
[32m+[m[32m        for kw in kw_strings:[m
[32m+[m[32m            if kw in kw_index:[m
[32m+[m[32m                kw_index[kw]["frequency"] += 1[m
[32m+[m[32m            else:[m
[32m+[m[32m                kw_index[kw] = {"keyword": kw, "frequency": 1}  # embedding later[m
[32m+[m
[32m+[m[32m        # write back flattened list[m
[32m+[m[32m        doc["keywords"] = list(kw_index.values())[m
     [m
[32m+[m[32m    # ────────────────────────────────────────────────────────────────────────[m
[32m+[m[32m    # 4.5 𝗦𝗮𝗻𝗶𝘁𝘆 𝗰𝗵𝗲𝗰𝗸: print some merged documents[m
[32m+[m
[32m+[m[32m    print("\nSample of merged documents:")[m
[32m+[m[32m    for r_id, doc in list(rmap.items())[:5]:  # show first 5 documents[m
[32m+[m[32m        print(f"r_id: {r_id}, keywords: {len(doc['keywords'])}")[m
[32m+[m[32m        for kw in doc["keywords"][:3]:  # show first 3 keywords[m
[32m+[m[32m            print(f"  - {kw['keyword']} (freq: {kw['frequency']})")[m
[32m+[m[32m            if "embedding" in kw and kw["embedding"] is not None:[m
[32m+[m[32m                print(f"    Embedding: {kw['embedding'][:5]}...")[m
[32m+[m[32m    print(f"Total documents processed: {len(rmap)}")[m
[32m+[m
[32m+[m[32m    # ────────────────────────────────────────────────────────────────────────[m
[32m+[m[32m    # 5. 𝗖𝗼𝗺𝗽𝗶𝗹𝗲 𝗸𝗲𝘆𝘄𝗼𝗿𝗱𝘀 𝗻𝗲𝗲𝗱𝗶𝗻𝗴 𝗲𝗺𝗯𝗲𝗱𝗱𝗶𝗻𝗴𝘀[m
[32m+[m[32m    pending = [][m
[32m+[m[32m    for d in rmap.values():[m
[32m+[m[32m        for kw_obj in d["keywords"]:[m
[32m+[m[32m            if "embedding" not in kw_obj or kw_obj["embedding"] is None:[m
[32m+[m[32m                pending.append(kw_obj["keyword"])[m
[32m+[m
[32m+[m[32m    # unique while preserving order[m
[32m+[m[32m    seen = set()[m
[32m+[m[32m    unique_pending = [k for k in pending if not (k in seen or seen.add(k))][m
[32m+[m[32m    print(f"{len(unique_pending)} embeddings to generate…")[m
[32m+[m
[32m+[m[32m    # ────────────────────────────────────────────────────────────────────────[m
[32m+[m[32m    # 5.5 𝗦𝗮𝗻𝗶𝘁𝘆 𝗰𝗵𝗲𝗰𝗸: print some pending keywords[m
[32m+[m
[32m+[m[32m    print("\nSample of pending keywords for embedding:")[m
[32m+[m[32m    for kw in unique_pending[:10]:  # show first 10 keywords[m
[32m+[m[32m        print(f"  - {kw}")[m
[32m+[m[32m    print(f"Total unique pending keywords: {len(unique_pending)}")[m
[32m+[m
[32m+[m[32m    # sys.exit(0)[m
[32m+[m
[32m+[m[32m    # ────────────────────────────────────────────────────────────────────────[m
[32m+[m[32m    # 6. 𝗚𝗲𝗻𝗲𝗿𝗮𝘁𝗲 𝗲𝗺𝗯𝗲𝗱𝗱𝗶𝗻𝗴𝘀[m
[32m+[m[32m    BATCH_SIZE = 512[m
[32m+[m[32m    emb_map: dict[str, list[float]] = {}[m
[32m+[m[32m    for start in tqdm(range(0, len(unique_pending), BATCH_SIZE), desc="Embedding"):[m
[32m+[m[32m        batch = unique_pending[start:start + BATCH_SIZE][m
[32m+[m[32m        vectors = embed_small(batch)[m
[32m+[m[32m        emb_map.update({kw: list(vec) for kw, vec in zip(batch, vectors)})[m
[32m+[m
[32m+[m[32m    # attach embeddings[m
[32m+[m[32m    for d in rmap.values():[m
[32m+[m[32m        for kw_obj in d["keywords"]:[m
[32m+[m[32m            if "embedding" not in kw_obj or kw_obj["embedding"] is None:[m
[32m+[m[32m                kw_obj["embedding"] = emb_map.get(kw_obj["keyword"])[m
[32m+[m
[32m+[m[32m    # ────────────────────────────────────────────────────────────────────────[m
[32m+[m[32m    # 6.5 Print some documents to be updated for sanity check[m
[32m+[m[32m    print("\nSample of updated documents:")[m
[32m+[m[32m    for r_id, doc in list(rmap.items())[:5]:  # show first 5 documents[m
[32m+[m[32m        print(f"r_id: {r_id}, keywords: {len(doc['keywords'])}")[m
[32m+[m[32m        for kw in doc["keywords"][:3]:  # show first 3 keywords[m
[32m+[m[32m            print(f"  - {kw['keyword']} (freq: {kw['frequency']})")[m
[32m+[m[32m            if kw.get("embedding"):[m
[32m+[m[32m                print(f"    Embedding: {kw['embedding'][:5]}...")[m[41m   [m
[32m+[m
[32m+[m[32m    # ────────────────────────────────────────────────────────────────────────[m
[32m+[m[32m    # 7. 𝗕𝘂𝗹𝗸-𝘂𝗽𝘀𝗲𝗿𝘁 𝗯𝗮𝗰𝗸 𝘁𝗼 MongoDB (only keywords field)[m
[32m+[m[32m    print("Writing back to MongoDB…")[m
[32m+[m[32m    ops = [[m
[32m+[m[32m        UpdateOne([m
[32m+[m[32m            {"r_id": d["r_id"]},[m
[32m+[m[32m            {"$set": {"keywords": d["keywords"]}},[m
[32m+[m[32m            upsert=True,[m
[32m+[m[32m        )[m
[32m+[m[32m        for d in rmap.values()[m
[32m+[m[32m    ][m
[32m+[m[32m    if ops:[m
[32m+[m[32m        result = restaurant_keywords_collection.bulk_write(ops, ordered=False)[m
[32m+[m[32m        print("Bulk write complete:", result.bulk_api_result)[m
[32m+[m[32m    else:[m
[32m+[m[32m        print("No changes detected.")[m
[32m+[m
 [m
[32m+[m[32m# ────────────────────────────────────────────────────────────────────────────────[m
 if __name__ == "__main__":[m
[31m-    main()[m
\ No newline at end of file[m
[32m+[m[32m    main()[m
[1mdiff --git a/frontend/nginx.conf b/frontend/nginx.conf[m
[1mindex 941d7f3..31d27ba 100644[m
[1m--- a/frontend/nginx.conf[m
[1m+++ b/frontend/nginx.conf[m
[36m@@ -11,9 +11,6 @@[m [mhttp {[m
     sendfile      on;[m
     keepalive_timeout  65;[m
 [m
[31m-    ##[m
[31m-    ## 1️⃣  MAIN SERVER BLOCK[m
[31m-    ##[m
     server {[m
         # listen for HTTP on port 80 (container-internal) – docker-compose maps it[m
         listen 80;[m
